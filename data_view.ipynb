{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import re\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import random\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(cv2.imread(\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = cv2.imread(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv = pd.read_csv(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv[\"label_len\"] = train_csv[\"label\"].apply(lambda x:len(x))\n",
    "train_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "for i in range(len(train_csv)):\n",
    "    jpg_file = train_csv.iloc[i][\"label\"]\n",
    "    if len(jpg_file) == 9:\n",
    "        cnt+=1\n",
    "cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    rand_idx = random.randrange(0,len(train_csv))\n",
    "    csv_row = train_csv.iloc[rand_idx]\n",
    "    jpg_file = csv_row[\"img_path\"]\n",
    "    img = cv2.imread(jpg_file)\n",
    "    if img.shape[0] >= 100:\n",
    "        break\n",
    "print(csv_row[\"label\"])\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(cv2.resize(img,dsize=(200,100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoImageProcessor\n",
    "import cv2\n",
    "\n",
    "from tacobox import Taco\n",
    "# creating taco object for augmentation (checkout Easter2.0 paper)\n",
    "mytaco = Taco(\n",
    "    cp_vertical=0.2,\n",
    "    cp_horizontal=0.25,\n",
    "    max_tw_vertical=100,\n",
    "    min_tw_vertical=10,\n",
    "    max_tw_horizontal=50,\n",
    "    min_tw_horizontal=10\n",
    ")\n",
    "\n",
    "def apply_taco_augmentations(input_img):\n",
    "    random_value = random.random()\n",
    "    if random_value <= 0.9:\n",
    "        augmented_img = mytaco.apply_vertical_taco(\n",
    "            input_img, \n",
    "            corruption_type='random'\n",
    "        )\n",
    "    else:\n",
    "        augmented_img = input_img\n",
    "    return augmented_img\n",
    "vconcat_flag = False\n",
    "hconcat_flag = True\n",
    "image_processor = AutoImageProcessor.from_pretrained(\"microsoft/swinv2-large-patch4-window12to24-192to384-22kto1k-ft\")\n",
    "max_label_len = max(train_csv[\"label\"].apply(lambda x:len(x)))\n",
    "img1_label = \"test1\"\n",
    "img2_label = \"test22\"\n",
    "while True:\n",
    "    rand_idx1 = random.randrange(0,len(train_csv))\n",
    "    csv_row1 = train_csv.iloc[rand_idx1]\n",
    "    img1_label = csv_row1[\"label\"]\n",
    "    jpg_file1 = csv_row1[\"img_path\"]\n",
    "    img1 = cv2.imread(jpg_file1)\n",
    "    \n",
    "\n",
    "    rand_idx2 = random.randrange(0,len(train_csv))\n",
    "    csv_row2 = train_csv.iloc[rand_idx2]\n",
    "    img2_label = csv_row2[\"label\"]\n",
    "    jpg_file2 = csv_row2[\"img_path\"]\n",
    "    img2 = cv2.imread(jpg_file2)\n",
    "\n",
    "    # 둘다 True인 경우 hconcat 결과로 반영되도록 의도함. vconcat은 해도 되는게 맞을지 모르겠음\n",
    "    if vconcat_flag:\n",
    "        img1 = cv2.resize(img1, dsize=(image_processor.size[\"width\"], img1.shape[0]))\n",
    "        img2 = cv2.resize(img2, dsize=(image_processor.size[\"width\"], img2.shape[0]))\n",
    "        if random.random() < 0.5:\n",
    "            img_result = cv2.vconcat([img1,img2])\n",
    "            label_result = img1_label + img2_label\n",
    "        else:\n",
    "            img_result = cv2.vconcat([img2,img1])\n",
    "            label_result = img2_label + img1_label\n",
    "\n",
    "    if hconcat_flag:\n",
    "        img1 = cv2.resize(img1, dsize=(img1.shape[1], image_processor.size[\"height\"]))\n",
    "        img2 = cv2.resize(img2, dsize=(img2.shape[1], image_processor.size[\"height\"]))\n",
    "        if random.random() < 0.5:\n",
    "            img_result = cv2.hconcat([img1,img2])\n",
    "            label_result = img1_label + img2_label\n",
    "        else:\n",
    "            img_result = cv2.hconcat([img2,img1])\n",
    "            label_result = img2_label + img1_label\n",
    "    if img1_label != img2_label and len(img1_label) + len(img2_label) <= 8:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from utils.dataset_utils import get_dataset\n",
    "import random\n",
    "from literal import RawDataColumns, DatasetColumns\n",
    "from transformers import AutoImageProcessor\n",
    "train_dataset = get_dataset('data/png_preprocess/train.csv')\n",
    "test_dataset = get_dataset('data/png_preprocess/test.csv')\n",
    "image_processor = AutoImageProcessor.from_pretrained(\"daekeun-ml/ko-trocr-base-nsmc-news-chatbot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_idx = random.randint(0,len(train_dataset)-1)\n",
    "print(train_dataset[41288][\"labels\"])\n",
    "plt.imshow(train_dataset[41288][DatasetColumns.pixel_values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resized = image_processor.resize(np.array(train_dataset[41288][DatasetColumns.pixel_values].convert(\"RGB\")),\n",
    "                                size=(image_processor.size[\"height\"],image_processor.size[\"width\"]),\n",
    "                                resample=2)\n",
    "plt.imshow(resized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ori = cv2.imread(\"data/train_png/TRAIN_041288.png\")\n",
    "plt.imshow(ori)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resized = image_processor.resize(ori,\n",
    "                                size=(image_processor.size[\"height\"],image_processor.size[\"width\"]),\n",
    "                                resample=2)\n",
    "plt.imshow(resized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "test = train_dataset[41288][DatasetColumns.pixel_values].load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(train_dataset[41288][DatasetColumns.pixel_values].convert(\"RGB\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = list()\n",
    "for text in train_csv[\"label\"]:\n",
    "    for char in text:\n",
    "        test.append(char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"snunlp/KR-BERT-char16424\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for text in train_csv[\"label\"]:\n",
    "    token = tokenizer.encode(text)\n",
    "    if 1 in token:\n",
    "        print(\"yes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = get_dataset(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=i+1\n",
    "print(test[i][\"labels\"])\n",
    "test[i][\"pixel_values\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = get_dataset(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv = pd.read_csv(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[11410][\"pixel_values\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lists = list(train_csv[train_csv[\"label\"]==\"심통\"].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[lists.pop()][\"pixel_values\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dee5e68f3bea899a9b45c01c51548e1d011d5be3731617f6f08dcbf2dd5fe500"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
